{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../TrainingSamples\"\n",
    "max_Star = 0\n",
    "for class_name in os.listdir(input_dir):\n",
    "    if class_name in [\".DS_Store\", \"readme.md\", \"previous\", \"Dataset_Details\"]:\n",
    "        continue\n",
    "    class_path = os.path.join(input_dir, class_name)\n",
    "    starpath = os.path.join(class_path, \"results.json\")\n",
    "    with open(starpath, 'r') as json_file:\n",
    "        star_df = json.load(json_file)\n",
    "    for constellation, values in star_df.items():\n",
    "        if len(values[\"area\"]) > max_Star:\n",
    "            max_Star = len(values[\"area\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_normalize_data(data):\n",
    "    data_out = {}\n",
    "    for constellation, values in data.items():\n",
    "        sorted_indices = sorted(range(len(values[\"area\"])), key=lambda i: -values[\"area\"][i])\n",
    "        sorted_area = [values[\"area\"][i] for i in sorted_indices]\n",
    "        sorted_x = [values[\"x\"][i] for i in sorted_indices]\n",
    "        sorted_y = [values[\"y\"][i] for i in sorted_indices]\n",
    "        xx = [i**2 for i in sorted_x]\n",
    "        yy = [i**2 for i in sorted_y]\n",
    "        xy = [sorted_x[i]*sorted_y[i] for i in range(len(sorted_x))]\n",
    "        normalized_values = {\n",
    "           \"area\": [(a - min(sorted_area)) / (max(sorted_area) - min(sorted_area)) for a in sorted_area],\n",
    "           \"x\": [(x - np.mean(sorted_x)) / np.std(sorted_x) for x in sorted_x],\n",
    "           \"y\": [(y - np.mean(sorted_y)) / np.std(sorted_y) for y in sorted_y],\n",
    "           \"x*x\": [(i - np.mean(xx)) / np.std(xx) for i in xx],\n",
    "           \"y*y\": [(i - np.mean(yy)) / np.std(yy) for i in yy],\n",
    "           \"x*y\": [(i - np.mean(xy)) / np.std(xy) for i in xy]\n",
    "        }\n",
    "        # stacked_array = np.column_stack((sorted_x, sorted_y))\n",
    "        #pca = PCA(n_components=1)\n",
    "        #print(\"stack\")\n",
    "        #print(stacked_array)\n",
    "        #pca.fit(stacked_array)\n",
    "        #print(f\"{constellation} component\")\n",
    "        #print(pca.components_[0])\n",
    "        #coeff1 = pca.components_[0][0]\n",
    "        #coeff2 =pca.components_[0][1]\n",
    "        #normalized_values[\"coeff\"] = [coeff1, coeff2]\n",
    "        \n",
    "    #    values = {\n",
    "    #       \"area\": sorted_area,\n",
    "    #       \"x\": sorted_x,\n",
    "    #       \"y\": sorted_y\n",
    "    #    }\n",
    "        data_out[constellation] = normalized_values\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_vectors(data, max_stars, target):\n",
    "    feature_vectors = []\n",
    "    targets = []\n",
    "    for constellation, values in data.items():\n",
    "        feature_vector = []\n",
    "        real_attri = len(values[\"area\"])\n",
    "        for i in range(real_attri):\n",
    "            for key in [\"area\", \"x\", \"y\", \"x*x\", \"y*y\", \"x*y\"]:\n",
    "                feature_vector.append(values[key][i])\n",
    "        if real_attri < max_stars:\n",
    "            feature_vector += [0.0] *(max_stars*6 - real_attri*6)\n",
    "        else:\n",
    "            feature_vector = feature_vector[:max_stars * 6]\n",
    "        # feature_vector += values[\"coeff\"]\n",
    "        feature_vectors.append(feature_vector)\n",
    "        targets.append(target)\n",
    "    feature_vectors = np.array(feature_vectors)\n",
    "    targets = np.array(targets)\n",
    "    return feature_vectors, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to read corrdinates and radius of stars in every constellation\n",
    "input_dir = \"../TrainingSamples\"\n",
    "output_dir = \"../data_model\"\n",
    "\n",
    "attributes = None# coordinates and areas\n",
    "targets = None\n",
    "for class_name in os.listdir(input_dir):\n",
    "    if class_name in [\".DS_Store\", \"readme.md\", \"previous\", \"Dataset_Details\"]:\n",
    "        continue\n",
    "    class_path = os.path.join(input_dir, class_name)\n",
    "    starpath = os.path.join(class_path, \"results.json\")\n",
    "    with open(starpath, 'r') as json_file:\n",
    "        star_df = json.load(json_file)\n",
    "    attr, target = create_feature_vectors(sort_normalize_data(star_df), max_stars=max_Star, target=class_name.split(\"_\")[0])\n",
    "    if attributes is None:\n",
    "        attributes = attr\n",
    "    else:\n",
    "        try:\n",
    "            attributes = np.vstack((attributes, attr))\n",
    "        except:\n",
    "            print(attributes.shape)\n",
    "            print(attr.shape)\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    if targets is None:\n",
    "        targets = target\n",
    "    else:\n",
    "        targets = np.concatenate((targets, target))\n",
    "\n",
    "np.save(os.path.join(output_dir, \"star_coor_area_MLP.npy\"),  attributes)\n",
    "np.save(os.path.join(output_dir,\"labels_MLP.npy\") , targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 102)\n",
      "(1728,)\n"
     ]
    }
   ],
   "source": [
    "star = np.load(os.path.join(output_dir, \"star_coor_area_MLP.npy\"))\n",
    "labels = np.load(os.path.join(output_dir,\"labels_MLP.npy\"))\n",
    "print(star.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.71803765, -0.79372294, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        , -1.4360021 , -0.57534249, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        , -1.33406406, -0.85648781, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.        ,  1.05485699, -0.14749189, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        ,  1.14949122,  0.19919599, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        , -1.05196684,  0.14412404, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
